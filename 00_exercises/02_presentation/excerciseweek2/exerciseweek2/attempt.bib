
@article{morris_using_2019,
	title = {Using simulation studies to evaluate statistical methods},
	volume = {38},
	issn = {0277-6715, 1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/sim.8086},
	doi = {10.1002/sim.8086},
	abstract = {Simulation studies are computer experiments that involve creating data by pseudo‐random sampling. A key strength of simulation studies is the ability to understand the behavior of statistical methods because some “truth” (usually some parameter/s of interest) is known from the process of generating the data. This allows us to consider properties of methods, such as bias. While widely used, simulation studies are often poorly designed, analyzed, and reported. This tutorial outlines the rationale for using simulation studies and offers guidance for design, execution, analysis, reporting, and presentation. In particular, this tutorial provides a structured approach for planning and reporting simulation studies, which involves defining aims, data‐generating mechanisms, estimands, methods, and performance measures (“ADEMP”); coherent terminology for simulation studies; guidance on coding simulation studies; a critical discussion of key performance measures and their estimation; guidance on structuring tabular and graphical presentation of results; and new graphical presentations. With a view to describing recent practice, we review 100 articles taken from Volume 34 of
              Statistics in Medicine
              , which included at least one simulation study and identify areas for improvement.},
	language = {en},
	number = {11},
	urldate = {2025-09-11},
	journal = {Statistics in Medicine},
	author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
	month = may,
	year = {2019},
	pages = {2074--2102},
	file = {Morris et al. - 2019 - Using simulation studies to evaluate statistical m.pdf:C\:\\Users\\vijlb\\Zotero\\storage\\CXGU833A\\Morris et al. - 2019 - Using simulation studies to evaluate statistical m.pdf:application/pdf},
}

@article{lakens_when_2024,
	title = {When and {How} to {Deviate} {From} a {Preregistration}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/4.0},
	issn = {2474-7394},
	url = {https://online.ucpress.edu/collabra/article/10/1/117094/200749/When-and-How-to-Deviate-From-a-Preregistration},
	doi = {10.1525/collabra.117094},
	abstract = {As the practice of preregistration becomes more common, researchers need guidance in how to report deviations from their preregistered statistical analysis plan. A principled approach to the use of preregistration should not treat all deviations as problematic. Deviations from a preregistered analysis plan can both reduce and increase the severity of a test, as well as increase the validity of inferences. I provide examples of how researchers can present deviations from preregistrations and evaluate the consequences of the deviation when encountering 1) unforeseen events, 2) errors in the preregistration, 3) missing information, 4) violations of untested assumptions, and 5) falsification of auxiliary hypotheses. The current manuscript aims to provide a principled approach to deciding when to deviate from a preregistration and how to report deviations from an error-statistical philosophy grounded in methodological falsificationism. The goal is to help researchers reflect on the consequence of deviations from preregistrations by evaluating the test’s severity and the validity of the inference.},
	language = {en},
	number = {1},
	urldate = {2025-09-11},
	journal = {Collabra: Psychology},
	author = {Lakens, Daniël},
	editor = {Ravenzwaaij, Don Van},
	month = may,
	year = {2024},
	pages = {117094},
	file = {Lakens - 2024 - When and How to Deviate From a Preregistration.pdf:C\:\\Users\\vijlb\\Zotero\\storage\\F24VSQ3P\\Lakens - 2024 - When and How to Deviate From a Preregistration.pdf:application/pdf},
}

@article{van_den_akker_potential_2024,
	title = {The potential of preregistration in psychology: {Assessing} preregistration producibility and preregistration-study consistency.},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0},
	issn = {1939-1463, 1082-989X},
	shorttitle = {The potential of preregistration in psychology},
	url = {https://doi.apa.org/doi/10.1037/met0000687},
	doi = {10.1037/met0000687},
	abstract = {Study preregistration has become increasingly popular in psychology, but its potential to restrict researcher degrees of freedom has not yet been empirically veriﬁed. We used an extensive protocol to assess the producibility (i.e., the degree to which a study can be properly conducted based on the available information) of preregistrations and the consistency between preregistrations and their corresponding papers for 300 psychology studies. We found that preregistrations often lack methodological details and that undisclosed deviations from preregistered plans are frequent. These results highlight that biases due to researcher degrees of freedom remain possible in many preregistered studies. More comprehensive registration templates typically yielded more producible preregistrations. We did not ﬁnd that the producibility and consistency of preregistrations differed over time or between original and replication studies. Furthermore, we found that operationalizations of variables were generally preregistered more producible and consistently than other study parts. Inconsistencies between preregistrations and published studies were mainly encountered for data collection procedures, statistical models, and exclusion criteria. Our results indicate that, to unlock the full potential of preregistration, researchers in psychology should aim to write more producible preregistrations, adhere to these preregistrations more faithfully, and more transparently report any deviations from their preregistrations. This could be facilitated by training and education to improve preregistration skills, as well as the development of more comprehensive templates.},
	language = {en},
	urldate = {2025-09-11},
	journal = {Psychological Methods},
	author = {Van Den Akker, Olmo R. and Bakker, Marjan and Van Assen, Marcel A. L. M. and Pennington, Charlotte R. and Verweij, Leone and Elsherif, Mahmoud M. and Claesen, Aline and Gaillard, Stefan D. M. and Yeung, Siu Kit and Frankenberger, Jan-Luca and Krautter, Kai and Cockcroft, Jamie P. and Kreuer, Katharina S. and Evans, Thomas Rhys and Heppel, Frédérique M. and Schoch, Sarah F. and Korbmacher, Max and Yamada, Yuki and Albayrak-Aydemir, Nihan and Alzahawi, Shilaan and Sarafoglou, Alexandra and Sitnikov, Maksim M. and Děchtěrenko, Filip and Wingen, Sophia and Grinschgl, Sandra and Hartmann, Helena and Stewart, Suzanne L. K. and De Oliveira, Cátia M. F. and Ashcroft-Jones, Sarah and Baker, Bradley J. and Wicherts, Jelte M.},
	month = oct,
	year = {2024},
	file = {Van Den Akker et al. - 2024 - The potential of preregistration in psychology As.pdf:C\:\\Users\\vijlb\\Zotero\\storage\\LQ25TGNT\\Van Den Akker et al. - 2024 - The potential of preregistration in psychology As.pdf:application/pdf},
}

@article{stefan_big_2023,
	title = {Big little lies: a compendium and simulation of p-hacking strategies},
	language = {en},
	author = {Stefan, Angelika M and Schönbrodt, Felix D},
	year = {2023},
	file = {PDF:C\:\\Users\\vijlb\\Zotero\\storage\\DTFSE2BG\\Stefan and Schönbrodt - Big little lies a compendium and simulation of p-hacking strategies.pdf:application/pdf},
}

@article{simmons_false-positive_2011,
	title = {False-{Positive} {Psychology}: {Undisclosed} {Flexibility} in {Data} {Collection} and {Analysis} {Allows} {Presenting} {Anything} as {Significant}},
	volume = {22},
	issn = {0956-7976},
	shorttitle = {False-{Positive} {Psychology}},
	url = {https://doi.org/10.1177/0956797611417632},
	doi = {10.1177/0956797611417632},
	abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists’ nominal endorsement of a low rate of false-positive findings (≤ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
	language = {EN},
	number = {11},
	urldate = {2025-09-12},
	journal = {Psychological Science},
	author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
	month = nov,
	year = {2011},
	note = {Publisher: SAGE Publications Inc},
	pages = {1359--1366},
	file = {SAGE PDF Full Text:C\:\\Users\\vijlb\\Zotero\\storage\\74BLEAUN\\Simmons et al. - 2011 - False-Positive Psychology Undisclosed Flexibility in Data Collection and Analysis Allows Presenting.pdf:application/pdf},
}

@article{p_simmons_pre-registration_2021,
	title = {Pre-registration: {Why} and {How}},
	volume = {31},
	copyright = {© 2021 Society for Consumer Psychology},
	issn = {1532-7663},
	shorttitle = {Pre-registration},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jcpy.1208},
	doi = {10.1002/jcpy.1208},
	abstract = {In this article, we (1) discuss the reasons why pre-registration is a good idea, both for the field and individual researchers, (2) respond to arguments against pre-registration, (3) describe how to best write and review a pre-registration, and (4) comment on pre-registration’s rapidly accelerating popularity. Along the way, we describe the (big) problem that pre-registration can solve (i.e., false positives caused by p-hacking), while also offering viable solutions to the problems that pre-registration cannot solve (e.g., hidden confounds or fraud). Pre-registration does not guarantee that every published finding will be true, but without it you can safely bet that many more will be false. It is time for our field to embrace pre-registration, while taking steps to ensure that it is done right.},
	language = {en},
	number = {1},
	urldate = {2025-09-12},
	journal = {Journal of Consumer Psychology},
	author = {P. Simmons, Joseph and D. Nelson, Leif and Simonsohn, Uri},
	year = {2021},
	note = {\_eprint: https://myscp.onlinelibrary.wiley.com/doi/pdf/10.1002/jcpy.1208},
	keywords = {Open Science, P-Hacking., Research Integrity, Research Transparency},
	pages = {151--162},
	file = {Full Text PDF:C\:\\Users\\vijlb\\Zotero\\storage\\JH865H43\\P. Simmons et al. - 2021 - Pre-registration Why and How.pdf:application/pdf;Snapshot:C\:\\Users\\vijlb\\Zotero\\storage\\7R9W9S8B\\jcpy.html:text/html},
}

@article{claesen_comparing_2021,
	title = {Comparing dream to reality: an assessment of adherence of the first generation of preregistered studies},
	volume = {8},
	issn = {2054-5703},
	shorttitle = {Comparing dream to reality},
	doi = {10.1098/rsos.211037},
	abstract = {Preregistration is a method to increase research transparency by documenting research decisions on a public, third-party repository prior to any influence by data. It is becoming increasingly popular in all subfields of psychology and beyond. Adherence to the preregistration plan may not always be feasible and even is not necessarily desirable, but without disclosure of deviations, readers who do not carefully consult the preregistration plan might get the incorrect impression that the study was exactly conducted and reported as planned. In this paper, we have investigated adherence and disclosure of deviations for all articles published with the Preregistered badge in Psychological Science between February 2015 and November 2017 and shared our findings with the corresponding authors for feedback. Two out of 27 preregistered studies contained no deviations from the preregistration plan. In one study, all deviations were disclosed. Nine studies disclosed none of the deviations. We mainly observed (un)disclosed deviations from the plan regarding the reported sample size, exclusion criteria and statistical analysis. This closer look at preregistrations of the first generation reveals possible hurdles for reporting preregistered studies and provides input for future reporting guidelines. We discuss the results and possible explanations, and provide recommendations for preregistered research.},
	language = {eng},
	number = {10},
	journal = {Royal Society Open Science},
	author = {Claesen, Aline and Gomes, Sara and Tuerlinckx, Francis and Vanpaemel, Wolf},
	month = oct,
	year = {2021},
	pmid = {34729209},
	pmcid = {PMC8548785},
	keywords = {open science, preregistration, psychological science, researcher degrees of freedom, transparency},
	pages = {211037},
	file = {Full Text PDF:C\:\\Users\\vijlb\\Zotero\\storage\\F3CR9R8E\\Claesen et al. - 2021 - Comparing dream to reality an assessment of adherence of the first generation of preregistered stud.pdf:application/pdf},
}

@article{willroth_best_2024,
	title = {Best {Laid} {Plans}: {A} {Guide} to {Reporting} {Preregistration} {Deviations}},
	abstract = {Psychological scientists are increasingly using preregistration as a tool to increase the credibility of research findings. Many of the benefits of preregistration rest on the assumption that preregistered plans are followed perfectly. However, research suggests that this is the exception rather than the norm, and there are many reasons why researchers may deviate from their preregistered plans. Preregistration can still be a valuable tool, even in the presence of deviations, as long as those deviations are well documented and transparently reported. Unfortunately, most preregistration deviations in psychology go unreported or are reported in unsystematic ways. In the current article, we offer a solution to this problem by providing a framework for transparent and standardized reporting of preregistration deviations, which was developed by drawing on our own experiences with preregistration, existing unpublished templates, feedback from colleagues and reviewers, and the results of a survey of 34 psychology-journal editors. This framework provides a clear template for what to do when things do not go as planned. We conclude by encouraging researchers to adopt this framework in their own preregistered research and by suggesting that journals implement structural policies around the transparent reporting of preregistration deviations.},
	language = {en},
	author = {Willroth, Emily C and Atherton, Olivia E},
	year = {2024},
	file = {PDF:C\:\\Users\\vijlb\\Zotero\\storage\\LN5UD6IW\\Willroth and Atherton - Best Laid Plans A Guide to Reporting Preregistration Deviations.pdf:application/pdf},
}

@book{popper_logic_1959,
	address = {Oxford, England},
	series = {The logic of scientific discovery},
	title = {The logic of scientific discovery},
	abstract = {This treatise on scientific theories and methods is a translation by its author of the 1934 Viennese edition, with considerable rearrangement and the addition of numerous appendices and notes. Scientific theories are said to be systems of statements which logically imply some singular, existential propositions which in principle could be falsified by empirical observations. Metaphysical theories lack such implications but many scientific theories have been derived historically from metaphysical speculations. The latter are not meaningless but only untestable as initially formulated. No scientific theory is established as a truth about reality, but is vindicated for the purposes of a discipline by repeated failures to falsify it by means of approved empirical methods. The probability value of theories is interpreted in parallel terms. The concepts of testability and simplicity are systematically examined. Applications are made to a number of controversies in recent and contemporary physics. Some attempt is made to show the relationship between the defended position and the positions of various historical thinkers and schools of thought. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {Basic Books},
	author = {Popper, Karl R.},
	year = {1959},
	note = {Pages: 480},
}

@book{r_core_team_r_2024,
	address = {Vienna, Austria},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	year = {2024},
}
